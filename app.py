import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search, filter_by_topics

st.set_page_config(page_title="Semantic Assistant", layout="centered")
st.title("ü§ñ Semantic Assistant")

@st.cache_data
def get_data():
    return load_all_excels()

df = get_data()

# üìç –ë–ª–æ–∫ 1. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º
all_topics = sorted({topic for topics in df['topics'] for topic in topics})
selected_topics = st.multiselect("üìÇ –ü–æ–∫–∞–∑–∞—Ç—å —Ñ—Ä–∞–∑—ã –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º:", all_topics)

if selected_topics:
    filtered_df = df[df['topics'].apply(lambda topics: any(t in topics for t in selected_topics))]
    st.markdown("### üìã –§—Ä–∞–∑—ã —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —Ç–µ–º–∞—Ç–∏–∫–∞–º–∏:")
    for row in filtered_df.itertuples():
        st.markdown(f"- **{row.phrase_full}** ‚Üí {', '.join(row.topics)}")

st.divider()

# üìç –ë–ª–æ–∫ 2. –£–º–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
query = st.text_input("üîç –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞:")

if query:
    try:
        results = semantic_search(query, df)
        if results:
            st.markdown("### ü§ñ –£–º–Ω—ã–π –ø–æ–∏—Å–∫:")
            for score, phrase_full, topics in results:
                st.markdown(f"- **{phrase_full}** ‚Üí {', '.join(topics)} (_{score:.2f}_)")
        else:
            st.warning("–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à—ë–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.")

        exact_results = keyword_search(query, df)
        if exact_results:
            st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
            for phrase, topics in exact_results:
                st.markdown(f"- **{phrase}** ‚Üí {', '.join(topics)}")
        else:
            st.info("–¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")
